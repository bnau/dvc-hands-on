# Partage et utilisation de modèles

## Agenda

Durant cette étape, nous allons aborder les points suivants :

* Création d'artéfacts
* Attribution de commits à un environnement
* Utilisation d'un modèle pour un environnement donné

## Initialisation de l'environnement de travail

Récupérons ce qui a été généré à l'étape précédente:

```bash
git checkout chapter06
dvc remote add -d default gs://dvc-remote-storage-hands-on-${USER}
```

## Création d'artéfacts

Pour qu'un projet puisse classifier les images,
il aura besoin des fichiers `model.h5` et `base.h5`.

On va ajouter dans notre pipeline une étape qui va copier ces deux fichiers dans un dossier `models`:

```yaml
generate_artifact:
  cmd: mkdir models && cp *.h5 models
  deps:
    - model.h5
    - base.h5
  outs:
    - models
```

DVC propose une gestion d'artéfacts: il s'agit de fichiers générés par le projet et qui pourront être utilisés par d'autres systèmes.
Déclarons un artéfact appelé `cats-vs-dogs` qui va pointer vers le dossier `models`.

> Voir [https://dvc.org/doc/user-guide/project-structure/dvcyaml-files#artifacts](https://dvc.org/doc/user-guide/project-structure/dvcyaml-files#artifacts)

Il faut maintenant lancer la pipeline et commiter l'environnement de travail.

## Utilisation du modèle dans une appli web

Nous allons créer une petite application web qui exposera un endpoint `/cats-or-dogs/` qui prendra en entrée une image 
et qui renverra `cat` ou `dog` en fonction de la prédiction du modèle.

Plaçons-nous dans un nouveau dossier, par exemple `use_model`. Nous allons créer un fichier `app.py` qui contiendra :

```python
from PIL import Image
import keras.models
from tensorflow.keras.utils import load_img
from tensorflow.keras.preprocessing.image import smart_resize
import numpy as np
from keras.src.applications import imagenet_utils
from fastapi import FastAPI, File, UploadFile

model = keras.models.load_model("models/model.h5")
base_model = keras.models.load_model("models/base.h5")

def preprocess_image(file):
    image = Image.open(file.file)
    image.save(file.filename)
    image = load_img(file.filename)
    image = smart_resize(
        image, (180, 180), interpolation='bilinear'
    )
    image = np.reshape([image], (1, 180, 180, 3))
    image = imagenet_utils.preprocess_input(
        image, mode="caffe"
    )
    return image

app = FastAPI()
@app.post("/cats-or-dogs/")
async def create_upload_file(file: UploadFile = File(...)):
    if model.predict(base_model.predict(preprocess_image(file))) < 0.5:
        return "cat"
    else:
        return "dog"
```

Pour pouvoir fonctionner, l'application aura besoin des fichiers `model.h5` et `base.h5`, tous les deux placés dans un dossier `models`.
Dans un premier temps, on va copier manuellement le dossier généré par DVC dans le dossier courant puis vérifier que l'application fonctionne.

```bash
uvicorn app:app
```

Dans un autre terminal, on peut appeler l'endpoint avec la commande :

```bash
curl -F "file=@IMAGE_PATH" http://127.0.0.1:8000/cats-or-dogs/
```

## Téléchargement de l'artefact

Au lieu de copier manuellement les modèles, on pourrait utiliser DVC pour télécharger l'artéfact déclaré précédemment.

Pour cela, il faut d'abord tagger le commit qui contient l'artéfact que l'on souhaite déployer dans un format bien précis.
Le tag doit contenir les informations suivantes :

* Le nom de l'artéfact
* Le nom de l'environnement cible
* Le numéro de version de l'artéfact

Pour nous faciliter la tâche, nous allons utiliser un autre outil de ligne de commande : `gto`.

Pour tagger associer l'artefact généré par le dernier commit à un environnement fictif de `test`, on peut exécuter :

```bash
gto register cats-vs-dogs
gto assign cats-vs-dogs --stage test
```

Enfin, dans l'application web, on pourra récupérer l'artéfact de test avec la commande :

```bash
dvc artifacts get DVC_PROJECT_PATH cats-vs-dogs --stage test
```

## À retenir

* Nous avons créé deux projets. Un pour générer un modèle et un autre pour l'utiliser.
* Le projet qui génère le modèle n'a besoin que d'un repository Git et d'un stockage distant pour être reproductible. 
On pourrait donc mettre en place très facilement une pipeline de CI qui pour relancer la génération et analyser l'évolution des performances du modèle.
* Le deuxième n'a également besoin que du même repository Git et du même stockage distant pour être déployé avec la bonne version du modèle.
Si on veut déployer une nouvelle version de l'application, il suffira de le déclarer dans Git avec un nouveau tag.

Pour résumer, nous avons réussi à centraliser dans Git le code source, les dépendances extérieures et les informations relatives au déploiement.
Nous avons donc réussi à mettre en place les briques nécessaires pour atteindre une architecture GitOps.